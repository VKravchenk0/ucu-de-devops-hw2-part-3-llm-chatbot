# DevOps HW3: LLM Chatbot
Зроблено на Streamlit + Docker Model Runner.

Код для streamlit-частини взято з офіційного прикладу:  
https://streamlit.io/playground?example=llm_chat

## Налаштування Windows + WSL
`Docker desktop -> Settings -> AI -> Enable Docker Model Runner + Enable host-side TCP support`

## Запуск
```bash
docker compose up --build
```

## URL
http://localhost:8050

